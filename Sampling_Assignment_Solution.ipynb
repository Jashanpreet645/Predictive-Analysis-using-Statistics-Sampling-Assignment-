{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPV270TiPEiWYhGbU4tMcOA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jashanpreet645/Predictive-Analysis-using-Statistics-Sampling-Assignment-/blob/main/Sampling_Assignment_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "phvIf1XynpgL"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset\n",
        "df = pd.read_csv(\"/content/Creditcard_data.csv\")\n",
        "x = df.drop(\"Class\", axis = 1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "# Balancing Dataset (Oversampling)\n",
        "ros = RandomOverSampler(random_state = 42)\n",
        "x_balanced, y_balanced = ros.fit_resample(x, y)\n",
        "balanced_df = pd.DataFrame(x_balanced, columns = x.columns)\n",
        "balanced_df[\"Class\"] = y_balanced"
      ],
      "metadata": {
        "id": "5rJ_NS9xpQu-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling\n",
        "def simple_random_sampling(df, frac = 0.6):\n",
        "    return df.sample(frac = frac, random_state = 42)\n",
        "\n",
        "def systematic_sampling(df, step = 2):\n",
        "    return df.iloc[::step]\n",
        "\n",
        "def stratified_sampling(df, frac = 0.6):\n",
        "    return df.groupby(\"Class\", group_keys = False).apply(lambda x: x.sample(frac = frac, random_state = 42))\n",
        "\n",
        "def cluster_sampling(df):\n",
        "    df = df.copy()\n",
        "    df[\"Cluster\"] = df.index % 5\n",
        "    choosen_cluster = np.random.choice(df[\"Cluster\"].unique())\n",
        "    return df[df[\"Cluster\"] == choosen_cluster].drop(\"Cluster\", axis = 1)\n",
        "\n",
        "def bootstrap_sampling(df, n_samples):\n",
        "    return df.sample(n = n_samples, replace = True, random_state = 42)\n"
      ],
      "metadata": {
        "id": "8fOPu9jnpUQJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating Samples\n",
        "samples = {\n",
        "    \"Simple Random\": simple_random_sampling(balanced_df),\n",
        "    \"Systematic\": systematic_sampling(balanced_df),\n",
        "    \"Stratified\": stratified_sampling(balanced_df),\n",
        "    \"Cluster\": cluster_sampling(balanced_df),\n",
        "    \"Bootstrap\": bootstrap_sampling(balanced_df, len(balanced_df))\n",
        "}\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter = 1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state = 42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators = 100, random_state = 42),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Support Vector Machine\": SVC()\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYuAILQ-pXex",
        "outputId": "09d554d4-655f-4eb8-ff19-a4908c2c613a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-586358421.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby(\"Class\", group_keys = False).apply(lambda x: x.sample(frac = frac, random_state = 42))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Evaluation\n",
        "results = []\n",
        "for sample_name, sample_df in samples.items():\n",
        "    x = sample_df.drop(\"Class\", axis = 1)\n",
        "    y = sample_df[\"Class\"]\n",
        "    scaler = StandardScaler()\n",
        "    x_sclaed = scaler.fit_transform(x)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x_sclaed, y, test_size = 0.2, random_state = 42, stratify = y)\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(x_train, y_train)\n",
        "        y_pred = model.predict(x_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "        results.append({\n",
        "            \"Sampling Technique\": sample_name,\n",
        "            \"Model\": model_name,\n",
        "            \"Accuracy\": accuracy\n",
        "        })\n"
      ],
      "metadata": {
        "id": "bqLYvWrqpcA2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Table\n",
        "results_df = pd.DataFrame(results)\n",
        "accuracy_table = (\n",
        "    results_df\n",
        "    .pivot(index = \"Model\", columns = \"Sampling Technique\", values = \"Accuracy\")\n",
        "    .round(2)\n",
        ")\n",
        "print(\"\\n Accuracy Table (Sampling x Model):\")\n",
        "print(accuracy_table)\n",
        "\n",
        "# Best Sampling Technique per Model\n",
        "best_sampling = accuracy_table.idxmax(axis = 1)\n",
        "print(\"\\n Best Sampling Technique per Model:\")\n",
        "print(best_sampling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jyE-gRopePf",
        "outputId": "918a4e67-35ba-43e1-c65b-7d49e58a50a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy Table (Sampling x Model):\n",
            "Sampling Technique      Bootstrap  Cluster  Simple Random  Stratified  \\\n",
            "Model                                                                   \n",
            "Decision Tree               99.67    96.72          99.46       98.37   \n",
            "Logistic Regression         94.77    93.44          94.02       92.93   \n",
            "Naive Bayes                 82.35    59.02          69.02       79.89   \n",
            "Random Forest              100.00   100.00         100.00      100.00   \n",
            "Support Vector Machine      98.04    96.72          97.28       98.91   \n",
            "\n",
            "Sampling Technique      Systematic  \n",
            "Model                               \n",
            "Decision Tree                99.35  \n",
            "Logistic Regression          90.85  \n",
            "Naive Bayes                  86.93  \n",
            "Random Forest               100.00  \n",
            "Support Vector Machine       96.73  \n",
            "\n",
            " Best Sampling Technique per Model:\n",
            "Model\n",
            "Decision Tree              Bootstrap\n",
            "Logistic Regression        Bootstrap\n",
            "Naive Bayes               Systematic\n",
            "Random Forest              Bootstrap\n",
            "Support Vector Machine    Stratified\n",
            "dtype: object\n"
          ]
        }
      ]
    }
  ]
}